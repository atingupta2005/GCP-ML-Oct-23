{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cebabe4",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "-  01 -  BigQuery - Table Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cef71",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63e4ffbd-4d77-4074-b84a-a9a10fe0b606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fifth-sprite-402605'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b255bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '02c'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-1'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3bf8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import kfp\n",
    "from kfp.v2 import compiler\n",
    "#import kfp.v2.dsl as dsl\n",
    "#import google_cloud_pipeline_components as gcc_aip\n",
    "from google_cloud_pipeline_components.v1.dataset import TabularDatasetCreateOp\n",
    "from google_cloud_pipeline_components.v1.automl.training_job import AutoMLTabularTrainingJobRunOp\n",
    "from google_cloud_pipeline_components.v1.endpoint import EndpointCreateOp, ModelDeployOp\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a4860",
   "metadata": {},
   "source": [
    "Set client objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0f88c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14fbbc",
   "metadata": {},
   "source": [
    "Set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f65b2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{DATANAME}/models/{NOTEBOOK}\"\n",
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87b637-25dd-436f-88e7-2553b4a9296d",
   "metadata": {},
   "source": [
    "## Authenticate to GCP\n",
    "- Note: Open shell and run below commanduth list\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa3079-77d1-449c-824e-00eeb6b37255",
   "metadata": {},
   "source": [
    "```\n",
    "sudo rm -rf ~/.gsutil\n",
    "sudo rm -rf ~/.config/gcloud\n",
    "git pull\n",
    "sudo apt install unzip \n",
    "unzip -n fifth-sprite-402605-f2105f411b52.zip\n",
    "gcloud auth login --cred-file=fifth-sprite-402605-f2105f411b52.json\n",
    "gcloud init --console-only\n",
    "gcloud auth application-default login\n",
    "gcloud config set project PROJECT_ID\n",
    "gcloud auth list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c68630e-4fe3-473d-abb3-16d39fb782e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'117917517031-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9abf0efb-bb7b-49d3-a1e9-3e365ca2bbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/editor\n",
      "roles/owner\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54fb72e-982b-4fc3-a3ef-a8c15ee3e822",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f15187",
   "metadata": {},
   "source": [
    "Clean environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7383876",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c3499",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline (KFP) Definition\n",
    "- Flow\n",
    "    - Create Vertex AI Dataset from link to BigQuery table\n",
    "    - Create Vertex AI AutoML Tabular Training Job\n",
    "    - Create Endpoint and Depoy trained model\n",
    "    \n",
    "Define a Job:\n",
    "- Consider Weighting\n",
    "- Model Type\n",
    "- Optimization Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb85abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_LIMIT = \"1\"  # vCPUs\n",
    "MEMORY_LIMIT = \"1G\"\n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "    name = f'kfp-{NOTEBOOK}-{DATANAME}-{TIMESTAMP}',\n",
    "    pipeline_root = URI+'/'+str(TIMESTAMP)+'/kfp/'\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    dataname: str,\n",
    "    display_name: str,\n",
    "    deploy_machine: str,\n",
    "    bq_source: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    features: dict,\n",
    "    labels: dict \n",
    "):\n",
    "    \n",
    "    # dataset\n",
    "    dataset = TabularDatasetCreateOp(\n",
    "        project = project,\n",
    "        display_name = display_name,\n",
    "        bq_source = bq_source,\n",
    "        labels = labels\n",
    "    ).set_cpu_limit(CPU_LIMIT).set_memory_limit(MEMORY_LIMIT)\n",
    "    \n",
    "    # training\n",
    "    model = AutoMLTabularTrainingJobRunOp(\n",
    "        project = project,\n",
    "        display_name = display_name,\n",
    "        optimization_prediction_type = \"classification\",\n",
    "        optimization_objective = \"maximize-au-prc\",\n",
    "        budget_milli_node_hours = 1000,\n",
    "        disable_early_stopping=False,\n",
    "        column_specs = features,\n",
    "        dataset = dataset.outputs['dataset'],\n",
    "        target_column = var_target,\n",
    "        predefined_split_column_name = 'splits',\n",
    "        labels = labels\n",
    "    ).set_cpu_limit(CPU_LIMIT).set_memory_limit(MEMORY_LIMIT)\n",
    "    \n",
    "    # Endpoint: Creation\n",
    "    endpoint = EndpointCreateOp(\n",
    "        project = project,\n",
    "        display_name = display_name,\n",
    "        labels = labels\n",
    "    )\n",
    "    \n",
    "    # Endpoint: Deployment of Model\n",
    "    deployment = ModelDeployOp(\n",
    "        model = model.outputs[\"model\"],\n",
    "        endpoint = endpoint.outputs[\"endpoint\"],\n",
    "        dedicated_resources_min_replica_count = 1,\n",
    "        dedicated_resources_max_replica_count = 1,\n",
    "        traffic_split = {\"0\": 100},\n",
    "        dedicated_resources_machine_type= deploy_machine\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7cda6",
   "metadata": {},
   "source": [
    "---\n",
    "## Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db3e8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func = pipeline,\n",
    "    package_path = f\"{DIR}/{NOTEBOOK}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3a04e",
   "metadata": {},
   "source": [
    "Move compiled pipeline files to GCS Bucket\n",
    "- Note: Before running below command, nake sure that you executed below command on the shell cli\n",
    "   - gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0df11e5c-801c-4745-8ed5-0a9acebc8963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://fifth-sprite-402605/fraud/models/02c'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "671d4cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://temp/02c/02c.json [Content-Type=application/json]...\n",
      "/ [1 files][ 46.7 KiB/ 46.7 KiB]                                                \n",
      "Operation completed over 1 objects/46.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {DIR}/{NOTEBOOK}.json {URI}/{TIMESTAMP}/kfp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45241ff1",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Vertex AI Pipeline Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed3319-fac1-45bb-9483-e02cfd4e0e3e",
   "metadata": {},
   "source": [
    "Get features dictionary for the pipeline input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ad629ff-3843-4e54-8a80-27bd7bb20cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names\n",
    "query = f\"SELECT * FROM {DATANAME}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{DATANAME}_prepped'\"\n",
    "schema = bq.query(query).to_dataframe()\n",
    "OMIT = VAR_OMIT.split() + [VAR_TARGET, 'splits']\n",
    "features = schema[~schema.column_name.isin(OMIT)].column_name.tolist()\n",
    "features = dict.fromkeys(features, 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf1a54-05f1-48f9-99e5-3de1c8f40bd5",
   "metadata": {},
   "source": [
    "Run The pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ad14259-d7fd-496c-b446-e27fd8603db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n1-standard-1'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPLOY_COMPUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5dd3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    template_path = f\"{URI}/{TIMESTAMP}/kfp/{NOTEBOOK}.json\",\n",
    "    parameter_values = {\n",
    "        \"project\" : PROJECT_ID,\n",
    "        \"dataname\" : DATANAME,\n",
    "        \"display_name\" : f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "        \"deploy_machine\" : DEPLOY_COMPUTE,\n",
    "        \"bq_source\" : f'bq://{PROJECT_ID}.{DATANAME}.{DATANAME}_prepped',\n",
    "        \"var_target\" : VAR_TARGET,\n",
    "        \"var_omit\" : VAR_OMIT,\n",
    "        \"features\" : features,\n",
    "        \"labels\" : {'notebook': NOTEBOOK}       \n",
    "    },\n",
    "    labels = {'notebook': NOTEBOOK},\n",
    "    enable_caching=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9aa521d-e845-4432-b728-518934262b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'117917517031-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ee521df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/117917517031/locations/us-central1/pipelineJobs/kfp-02c-fraud-20231024031909-20231024032709\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/117917517031/locations/us-central1/pipelineJobs/kfp-02c-fraud-20231024031909-20231024032709')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/kfp-02c-fraud-20231024031909-20231024032709?project=117917517031\n",
      "PipelineJob projects/117917517031/locations/us-central1/pipelineJobs/kfp-02c-fraud-20231024031909-20231024032709 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/117917517031/locations/us-central1/pipelineJobs/kfp-02c-fraud-20231024031909-20231024032709 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/117917517031/locations/us-central1/pipelineJobs/kfp-02c-fraud-20231024031909-20231024032709 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/117917517031/locations/us-central1/pipelineJobs/kfp-02c-fraud-20231024031909-20231024032709 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/117917517031/locations/us-central1/pipelineJobs/kfp-02c-fraud-20231024031909-20231024032709 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [endpoint-create, tabular-dataset-create].; Job (project_id = fifth-sprite-402605, job_id = 7595808404967260160) is failed due to the above error.; Failed to handle the job: {project_number = 117917517031, job_id = 7595808404967260160}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSERVICE_ACCOUNT\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pyenv/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:319\u001b[0m, in \u001b[0;36mPipelineJob.run\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run this configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m network \u001b[38;5;241m=\u001b[39m network \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mnetwork\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pyenv/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:817\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    816\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    820\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/pyenv/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:356\u001b[0m, in \u001b[0;36mPipelineJob._run\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to ensure network synchronization and to run\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03mthe configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    351\u001b[0m     service_account\u001b[38;5;241m=\u001b[39mservice_account,\n\u001b[1;32m    352\u001b[0m     network\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[1;32m    353\u001b[0m     create_request_timeout\u001b[38;5;241m=\u001b[39mcreate_request_timeout,\n\u001b[1;32m    354\u001b[0m )\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pyenv/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:595\u001b[0m, in \u001b[0;36mPipelineJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# Error is only populated when the job state is\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01min\u001b[39;00m _PIPELINE_ERROR_STATES:\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob failed with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    597\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [endpoint-create, tabular-dataset-create].; Job (project_id = fifth-sprite-402605, job_id = 7595808404967260160) is failed due to the above error.; Failed to handle the job: {project_number = 117917517031, job_id = 7595808404967260160}\"\n"
     ]
    }
   ],
   "source": [
    "response = pipeline.run(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c8e67-bceb-4629-a246-6a6f18a1c530",
   "metadata": {},
   "source": [
    "Visual Representation of the pipeline can be viewed in the colsole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd262fe9-0693-446a-be88-779e15fb0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Review the Pipeline as it runs here:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/pipelines/runs/{pipeline.resource_name.split('/')[-1]}?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d982aa6-2999-47f6-92a0-01510050e681",
   "metadata": {},
   "source": [
    "Retrieve the pipeline information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'kfp-{NOTEBOOK}-{DATANAME}-{TIMESTAMP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0523ffaa-9dfb-41cb-b7b5-6cc6ddae1613",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Evaluation\n",
    "While the model above was trained using AutoML with the API, it is still possible to review the evaluation metrics directly in the Google Cloud Console.  Just visit the Models section of Vertex AI service and select the model and it will present the evaluation metrics with many helpful visuals.\n",
    "\n",
    "It is also possible to retrieve the evaluation metrics for you model using the API. \n",
    "\n",
    "For more information review [this page](https://cloud.google.com/vertex-ai/docs/training/evaluating-automl-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1c3f1",
   "metadata": {},
   "source": [
    "Get the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6634c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = aiplatform.Model.list(filter=f'labels.notebook={NOTEBOOK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7b61b-ad0f-487b-8dc6-ac8ed12e6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]\n",
    "model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71227e04-8bb0-46d5-862e-3fddfe0361ae",
   "metadata": {},
   "source": [
    "Retrives the aggregate model evalution metrics for the model as a whole.  \n",
    "\n",
    "Either:\n",
    "- First, use `model.list_model_evaluations()` to retrieve the evaluation id, then use `model.get_model_evaluation(evaluation_id = )` for the evaluation id\n",
    "- Or, use `.get_model_evaluation()` and it will retrieve the first model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5d7e0-6ef5-4787-a5d0-953848318989",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.get_model_evaluation().to_dict() # get first evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35848c5d-d9af-4109-abd5-f093adba2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763abbd-d2f4-430a-9a03-9e5af413b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation['metrics'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562dcf6-02af-4185-96be-5b8b77a5cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation['metrics']['auPrc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd1c4b-00a3-4b2c-95a0-bb837307f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation['metrics']['confidenceMetrics'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa9551-2e4a-4673-b0d5-1ddec1233e0e",
   "metadata": {},
   "source": [
    "Review several of the metrics included in the evaluation.  Also, compare these to the results in the console view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd8a0e-cb68-4c45-bb58-c8622b9b0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Review this model in the console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}/versions/{model.version_id}/evaluations/{evaluation['name'].split('/')[-1]}?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6e04f-c0ec-4ad1-a8be-460cddcb0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation['metrics']['auPrc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9892b-eeac-4a64-aa9b-68a7a45a3e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(evaluation['metrics']['confusionMatrix']['annotationSpecs'])):\n",
    "    print('True Label = ', evaluation['metrics']['confusionMatrix']['annotationSpecs'][i]['displayName'], ' has Predicted labels = ', evaluation['metrics']['confusionMatrix']['rows'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266afe6-be3f-4565-afd9-cb839682df2c",
   "metadata": {},
   "source": [
    "For models with labels you can retrieve the evaluation metrics for each slice of the model as well using the .gapic api version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ce330-8b74-44ff-a71f-f7670a1d924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = aiplatform.gapic.ModelServiceClient(\n",
    "    client_options = {\n",
    "        'api_endpoint' : f'{REGION}-aiplatform.googleapis.com'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a6f0d-ab29-4825-a29e-335f5a1727e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = model_client.list_model_evaluation_slices(parent = evaluation['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b5c5a-d43c-4c77-8806-fa92f6438e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice in slices:\n",
    "    print('Label = ', slice.slice_.value, 'has auPrc = ', slice.metrics['auPrc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829782e",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269e25d",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bq.query(\n",
    "    query = f\"\"\"\n",
    "        SELECT * EXCEPT({VAR_TARGET}, splits, {VAR_OMIT})\n",
    "        FROM {DATANAME}.{DATANAME}_prepped\n",
    "        WHERE splits='TEST'\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['Time'] = pred['Time'].astype(str)\n",
    "newobs = pred.to_dict(orient='records')\n",
    "newobs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fde74e",
   "metadata": {},
   "source": [
    "Need to understand the format of variables that the predictions expect.  AutoML may convert the type of some variables. The following cells retrieve the model from the endpoint and its schemata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [json_format.ParseDict(newob, Value()) for newob in newobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61f206",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fefd9-e7c7-4971-8e6b-d630469f2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.Endpoint.list(filter=f'labels.notebook={NOTEBOOK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279cf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.list(filter=f'labels.notebook={NOTEBOOK}')[0]\n",
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c298d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances = instances) # or instances = newobs\n",
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.predictions[0]['classes'][np.argmax(prediction.predictions[0]['scores'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68781f2",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": [newobs[0]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b428c9d",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3523017",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d825b",
   "metadata": {},
   "source": [
    "---\n",
    "## Explanations\n",
    "Interpretation Guide\n",
    "- https://cloud.google.com/vertex-ai/docs/predictions/interpreting-results-automl#tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80280fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = endpoint.explain(instances = instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"attribution:\")\n",
    "print(\"baseline output\",explanation.explanations[0].attributions[0].baseline_output_value)\n",
    "print(\"instance output\",explanation.explanations[0].attributions[0].instance_output_value)\n",
    "print(\"output_index\",explanation.explanations[0].attributions[0].output_index)\n",
    "print(\"output display value\",explanation.explanations[0].attributions[0].output_display_name)\n",
    "print(\"approximation error\",explanation.explanations[0].attributions[0].approximation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afdc889-9620-4e5c-adf9-5ecf2238ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "features = []\n",
    "scores = []\n",
    "for k in explanation.explanations[0].attributions[0].feature_attributions:\n",
    "    features.append(k)\n",
    "    scores.append(explanation.explanations[0].attributions[0].feature_attributions[k])\n",
    "features = [x for _, x in sorted(zip(scores, features))]\n",
    "scores = sorted(scores)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(9, 9)\n",
    "ax.barh(features, scores)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

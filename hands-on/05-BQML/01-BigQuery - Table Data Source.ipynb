{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28f7fa2",
   "metadata": {},
   "source": [
    "\n",
    "# 01 - BigQuery - Table Data Source\n",
    "Use BigQuery to load and prepare data for machine learning:\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [00 - Environment Setup](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Download BigQuery Data to Pandas](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas)\n",
    "-  [BigQuery Template Notebooks](https://github.com/GoogleCloudPlatform/bigquery-notebooks/tree/main/notebooks/official/template_notebooks)\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/01_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/01_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c695d-002d-48ca-9d52-839f95fdfee0",
   "metadata": {},
   "source": [
    "---\n",
    "## Source Data\n",
    "\n",
    "**Overview**\n",
    "\n",
    "This notebook imports source data for this project into Google BigQuery.  All the remaining notebooks utilize BigQuery as the source and leverage API's native to the machine learning approaches they feature.\n",
    "\n",
    "In the enviornment setup notebook (00), a BigQuery source table was exported to CSV format in a Cloud Storage Bucket. This notebook, `01 - BigQuery - Table Data Source`, starts the machine learning lifecycle by importing source data and preparing it for machine learning.\n",
    "\n",
    "All of these workflows utilize tabular data to fit a supervised learning model: predict a target variable by learning patterns in feature columns.  The type of supervised learning used in these projects is classification: models with a target variable that has multiple discrete classes.  \n",
    "\n",
    "**The Data**\n",
    "\n",
    "The source data is first exported to Google Cloud Storage in CSV format below.  The BigQuery source table is `bigquery-public-data.ml_datasets.ulb_fraud_detection`.  This is a table of credit card transactions that are classified as fradulant, `Class = 1`, or normal `Class = 0`.    \n",
    "- The data can be researched further at this [Kaggle link](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "- Read mode about BigQuery public datasets [here](https://cloud.google.com/bigquery/public-data)\n",
    "\n",
    "**Description of the Data**\n",
    "\n",
    "This is a table of 284,807 credit card transactions classified as fradulant or normal in the column `Class`.  In order protect confidentiality, the original features have been transformed using [principle component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) into 28 features named `V1, V2, ... V28` (float).  Two descriptive features are provided without transformation by PCA:\n",
    "- `Time` (integer) is the seconds elapsed between the transaction and the earliest transaction in the table\n",
    "- `Amount` (float) is the value of the transaction\n",
    ">**Quick Note on PCA**<p>PCA is an unsupervised learning technique: there is not a target variable.  PCA is commonlly used as a variable/feature reduction technique.  If you have 100 features then you could reduce it to a number p (say 10) projected features.  The choice of this number is a balance of how well it can explain the variance of the full feature space and reducing the number of features.  Each projected feature is orthogonal to each other feature, meaning there is no correlation between these new projected features.</p>\n",
    "\n",
    "**Preparation of the Data**\n",
    "\n",
    "This notebook adds two columns to the source data and stores it in a new table with suffix `_prepped`.  \n",
    "- `transaction_id` (string) a unique id for the row/transaction\n",
    "- `splits` (string) this divided the tranactions into sets for `TRAIN` (80%), `VALIDATE` (10%), and `TEST` (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5046940",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae60b2",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa8ffed-d17e-47b2-a6a3-0441ef19fcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install google.cloud.aiplatform -U -q --user\n",
    "!pip install --upgrade gcsfs -U -q --user\n",
    "!pip install --upgrade google-cloud-bigquery -U -q --user\n",
    "!pip install --upgrade google-cloud-bigquery-storage -U -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411d71cf-c353-426a-afa7-9c089d1dbbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.cloud.storage==1.44.0 in /opt/conda/lib/python3.10/site-packages (1.44.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google.cloud.storage==1.44.0) (2.31.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google.cloud.storage==1.44.0) (1.16.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google.cloud.storage==1.44.0) (1.35.0)\n",
      "Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /opt/conda/lib/python3.10/site-packages (from google.cloud.storage==1.44.0) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google.cloud.storage==1.44.0) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google.cloud.storage==1.44.0) (2.6.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google.cloud.storage==1.44.0) (3.19.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0dev,>=1.29.0->google.cloud.storage==1.44.0) (1.60.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google.cloud.storage==1.44.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google.cloud.storage==1.44.0) (0.3.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google.cloud.storage==1.44.0) (68.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google.cloud.storage==1.44.0) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google.cloud.storage==1.44.0) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google.cloud.storage==1.44.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google.cloud.storage==1.44.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google.cloud.storage==1.44.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google.cloud.storage==1.44.0) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google.cloud.storage==1.44.0) (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install google.cloud.storage==1.44.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f0503a-e864-4170-ade9-0ebabd14efcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learned-pottery-399802'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a5bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '01'\n",
    "SERIES = '01'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud'\n",
    "\n",
    "# Data source for this series of notebooks: Described above\n",
    "BQ_SOURCE = 'bigquery-public-data.ml_datasets.ulb_fraud_detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a963be",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a37b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cebb6",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e515410",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6601398",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1e2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c3a89-d98f-471c-ae54-3b9157651f0b",
   "metadata": {},
   "source": [
    "---\n",
    "## Store the Source Data in GCS Storage Bucket\n",
    "Check to see if the export exist and create if not:\n",
    "- export from bigquery table to GCS bucket as CSV\n",
    "    - the table is referenced in the `BQ_SOURCE` variable at the top of this notebook\n",
    "- [Exporting Table Data](https://cloud.google.com/bigquery/docs/exporting-data#python)\n",
    "- [BigQuery Python Client](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_extract_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6144857f-1ecc-4712-925b-4de69b6df0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"{SERIES}/{EXPERIMENT}/data/{BQ_TABLE}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65714181-b946-4c5c-b990-6f7ac4f2ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the export ...\n"
     ]
    }
   ],
   "source": [
    "bucketDef = gcs.bucket(BUCKET)\n",
    "if storage.Blob(bucket = bucketDef, name = file).exists(gcs):\n",
    "    print(f'The file has already been created at: gs://{bucketDef.name}/{file}')\n",
    "else:\n",
    "    source = bigquery.TableReference.from_string(BQ_SOURCE)\n",
    "    extract = bq.extract_table(source = source, destination_uris = [f'gs://{bucketDef.name}/{file}'])\n",
    "    print('Creating the export ...')\n",
    "    extract.result()\n",
    "    print(f'Exported the table to: gs://{bucketDef.name}/{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c19f8-677e-4219-a0ff-bcfe1fd932a0",
   "metadata": {},
   "source": [
    "list files in the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed784872-405b-4d64-a70b-4482529b5fc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "JSONConnection.api_request() got an unexpected keyword argument 'extra_api_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbucketDef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_blobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSERIES\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mEXPERIMENT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/page_iterator.py:208\u001b[0m, in \u001b[0;36mIterator._items_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_items_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterator for each item returned.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iter(increment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m page:\n\u001b[1;32m    210\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/page_iterator.py:244\u001b[0m, in \u001b[0;36mIterator._page_iter\u001b[0;34m(self, increment)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_page_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m, increment):\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generator of pages of API responses.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m        Page: each page of items from the API.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/page_iterator.py:373\u001b[0m, in \u001b[0;36mHTTPIterator._next_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the next page in the iterator.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    Optional[Page]: The next page in the iterator or :data:`None` if\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m        there are no pages left.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_next_page():\n\u001b[0;32m--> 373\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next_page_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     items \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items_key, ())\n\u001b[1;32m    375\u001b[0m     page \u001b[38;5;241m=\u001b[39m Page(\u001b[38;5;28mself\u001b[39m, items, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_to_value, raw_page\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/page_iterator.py:432\u001b[0m, in \u001b[0;36mHTTPIterator._get_next_page_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_query_params()\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_HTTP_METHOD \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_HTTP_METHOD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_HTTP_METHOD \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_request(\n\u001b[1;32m    437\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_HTTP_METHOD, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, data\u001b[38;5;241m=\u001b[39mparams\n\u001b[1;32m    438\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/storage/_http.py:72\u001b[0m, in \u001b[0;36mConnection.api_request\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry:\n\u001b[1;32m     71\u001b[0m         call \u001b[38;5;241m=\u001b[39m retry(call)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mTypeError\u001b[0m: JSONConnection.api_request() got an unexpected keyword argument 'extra_api_info'"
     ]
    }
   ],
   "source": [
    "list(bucketDef.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f40c2ea7-0649-4073-88a4-3e47af62f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the files in the console here:\n",
      "https://console.cloud.google.com/storage/browser/learned-pottery-399802/01;tab=objects&project=learned-pottery-399802\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the files in the console here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SERIES};tab=objects&project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685eddc",
   "metadata": {},
   "source": [
    "---\n",
    "## Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cab37",
   "metadata": {},
   "source": [
    "List BigQuery datasets in the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b49b948-5fa8-4d4e-a7d3-b2adb19362c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecommerce\n",
      "feat_eng\n",
      "fraud\n",
      "housing\n",
      "housing_prices\n",
      "serverlessml\n",
      "takudzwa_taxi_fairr\n",
      "taxifare\n",
      "taxifaretinashe\n"
     ]
    }
   ],
   "source": [
    "datasets = list(bq.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b3aca",
   "metadata": {},
   "source": [
    "Create the dataset if missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61001b78-418f-42a1-a4c4-d74a1f3aff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "ds.location = REGION\n",
    "ds.labels = {'experiment': f'{EXPERIMENT}'}\n",
    "ds = bq.create_dataset(dataset = ds, exists_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a50638-515e-49d0-b479-25e92138ae96",
   "metadata": {},
   "source": [
    "List BigQuery datasets in the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b39f4471-38f4-4b97-8d9c-7ee3122dbee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecommerce\n",
      "feat_eng\n",
      "fraud\n",
      "housing\n",
      "housing_prices\n",
      "serverlessml\n",
      "takudzwa_taxi_fairr\n",
      "taxifare\n",
      "taxifaretinashe\n"
     ]
    }
   ],
   "source": [
    "datasets = list(bq.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eeac68",
   "metadata": {},
   "source": [
    "---\n",
    "## Create BigQuery Table\n",
    "- import data from Cloud Storage Bucket\n",
    "- [Loading CSV data from Cloud Storage](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv)\n",
    "- [BigQuery Python Client](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_extract_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86063a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Table ...\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 Not found: URI gs://learned-pottery-399802/01/01/data/fraud.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     table \u001b[38;5;241m=\u001b[39m \u001b[43mbq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBQ_PROJECT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBQ_DATASET\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBQ_TABLE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m table:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:1068\u001b[0m, in \u001b[0;36mClient.get_table\u001b[0;34m(self, table, retry, timeout)\u001b[0m\n\u001b[1;32m   1067\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m-> 1068\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.getTable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Table\u001b[38;5;241m.\u001b[39mfrom_api_repr(api_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:816\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    814\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    815\u001b[0m     ):\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/_http.py:484\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/learned-pottery-399802/datasets/fraud/tables/fraud?prettyPrint=false: Not found: Table learned-pottery-399802:fraud.fraud",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m job_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mLoadJobConfig(\n\u001b[1;32m     10\u001b[0m     write_disposition \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITE_TRUNCATE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     source_format \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mSourceFormat\u001b[38;5;241m.\u001b[39mCSV,\n\u001b[1;32m     12\u001b[0m     autodetect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     labels \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEXPERIMENT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m job \u001b[38;5;241m=\u001b[39m bq\u001b[38;5;241m.\u001b[39mload_table_from_uri(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucketDef\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, destination, job_config \u001b[38;5;241m=\u001b[39m job_config)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished creating table: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBQ_PROJECT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBQ_DATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBQ_TABLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:922\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    921\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m DEFAULT_RETRY \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry\u001b[39m\u001b[38;5;124m\"\u001b[39m: retry}\n\u001b[0;32m--> 922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AsyncJob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, retry\u001b[38;5;241m=\u001b[39mretry, polling\u001b[38;5;241m=\u001b[39mpolling)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Not found: URI gs://learned-pottery-399802/01/01/data/fraud.csv"
     ]
    }
   ],
   "source": [
    "from google.cloud.exceptions import NotFound\n",
    "try:\n",
    "    table = bq.get_table(f'{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')\n",
    "    if table:\n",
    "        print(f'The table already exists: {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')\n",
    "except NotFound as error:\n",
    "    print(f'Creating Table ...')\n",
    "    destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\")\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition = 'WRITE_TRUNCATE',\n",
    "        source_format = bigquery.SourceFormat.CSV,\n",
    "        autodetect = True,\n",
    "        labels = {'experiment': f'{EXPERIMENT}'}\n",
    "    )\n",
    "    job = bq.load_table_from_uri(f\"gs://{bucketDef.name}/{file}\", destination, job_config = job_config)\n",
    "    job.result()\n",
    "    print(f'Finished creating table: {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44285e37-6ac7-478d-9709-dd11a068a4dc",
   "metadata": {},
   "source": [
    "### Retrieve and Review a Sample From The Table:\n",
    "> **Note:** The `LIMIT 5` statement does limit the number of rows returned by BigQuery to 5 but BigQuery still does a full table scan.  If you have a table larger than 1GB and want to limit the rows scanned for a quick review like then then replacing `LIMIT 5` with `TABLESAMPLE SYSTEM (1 PERCENT)` would be more efficient.  For tables under 1GB it will still return the full table.  More on [Table Sampling](https://cloud.google.com/bigquery/docs/table-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11924cf8-a040-4ee5-85ae-788cba106b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` TABLESAMPLE SYSTEM (1 PERCENT)\n",
    "#LIMIT 5\n",
    "\"\"\"\n",
    "bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ccdce-e6a9-4735-9997-e5ae77a6f86c",
   "metadata": {},
   "source": [
    "### Check out this table in BigQuery Console:\n",
    "- Click: https://console.cloud.google.com/bigquery\n",
    "- Make sure project selected is the one from this notebook\n",
    "- Under Explore, expand this project and review the dataset and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439a1dc-dfdd-4c82-8302-8dc1ffe44d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Direct Link To This Project In BigQuery:\\nhttps://console.cloud.google.com/bigquery?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f133efb-8232-4b21-814f-23b815dc60f2",
   "metadata": {},
   "source": [
    "---\n",
    "## Review Data in BigQuery\n",
    "Additional SQL queries could be used to review the data.  This section shows moving the table to a Pandas dataframe for local review in Python:\n",
    "\n",
    "> **Note:** <p>This query only selects one column.  This means BigQuery scans less data as it does not process the other columns.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebf6f5-a178-4011-9ab6-fa8329c578c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT Class\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "\"\"\"\n",
    "df = bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f716e-8b9d-4c92-9b46-c166b869f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d17e5-07c3-48fd-b682-aa471f3548f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b34894",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Data for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c982157",
   "metadata": {},
   "source": [
    "Create a prepped version of the data with test/train splits using SQL DDL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50becbb-60ab-45f9-acd5-9beb5b6755f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped` AS\n",
    "WITH add_id AS(SELECT *, GENERATE_UUID() transaction_id FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`)\n",
    "SELECT *,\n",
    "    CASE \n",
    "        WHEN MOD(ABS(FARM_FINGERPRINT(transaction_id)),10) < 8 THEN \"TRAIN\" \n",
    "        WHEN MOD(ABS(FARM_FINGERPRINT(transaction_id)),10) < 9 THEN \"VALIDATE\"\n",
    "        ELSE \"TEST\"\n",
    "    END AS splits\n",
    "FROM add_id\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6e2a9-ec35-477c-9d50-429326acc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(job.ended-job.started).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991ff73-a545-4eed-a709-b8292efd89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if job.estimated_bytes_processed:\n",
    "    print(f'{job.estimated_bytes_processed/1000000} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b2c41",
   "metadata": {},
   "source": [
    "Review the test/train split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94adb9-81d7-4710-ac50-e0d93dd5523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT splits, count(*) as Count, 100*count(*) / (sum(count(*)) OVER()) as Percentage\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped`\n",
    "GROUP BY splits\n",
    "\"\"\"\n",
    "bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006ed11",
   "metadata": {},
   "source": [
    "Retrieve a subset of the data to a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea70141-07db-46b0-a31e-0968befcd37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT * \n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped`\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "data = bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d575d1",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

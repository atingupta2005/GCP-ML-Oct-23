{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO",
    "tags": []
   },
   "source": [
    "# Creating a Vertex AI Feature Store Using Pandas\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "1. Create Feature Store Resources.\n",
    "2. Ingest Feature Values into Entity Type from a Pandas DataFrame.\n",
    "3. Read/Online Serve Entity's Feature Values from Vertex AI Online Feature Store.\n",
    "4. Batch Serve Feature Values from Vertex AI Feature Store.\n",
    "5. Read the Updated Feature Values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4ZNLaf6T0lN"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook introduces Pandas support for Feature Store using Vertex AI SDK. For pre-requisites and introduction on Vertex AI SDK and Feature Store native support, please go through this [Colab notebook](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/feature_store/sdk-feature-store.ipynb).\n",
    "\n",
    "### Dataset\n",
    "\n",
    "This notebook uses a movie recommendation dataset as an example throughout all the notebooks including this one. The original task is to train a model to predict if a user is going to watch a movie and serve the model online.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, you may be able to get your project ID using `gcloud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dcdfccf50581"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"fifth-sprite-402605\"  # Replace with your project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "09021c90b34c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5c615e53149f"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Cdct_Lm7x2I_"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UvxYyGUimKw"
   },
   "source": [
    "## Create Feature Store Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buQBIv3ZL3A0"
   },
   "source": [
    "### Create Feature Store\n",
    "\n",
    "The method to create a Feature Store returns a\n",
    "[long-running operation](https://google.aip.dev/151) (LRO). An LRO starts an asynchronous job. LROs are returned for other API\n",
    "methods too, such as updating or deleting a featurestore. Running the code cell creates a featurestore and prints the process logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "D6uIWQeoBSr8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Featurestore\n",
      "Create Featurestore backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/operations/4227811805835034624\n",
      "Featurestore created. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions\n",
      "To use this Featurestore in another session:\n",
      "featurestore = aiplatform.Featurestore('projects/117917517031/locations/us-central1/featurestores/movie_predictions')\n"
     ]
    }
   ],
   "source": [
    "movie_predictions_feature_store = aiplatform.Featurestore.create(\n",
    "    featurestore_id=\"movie_predictions\",\n",
    "    online_store_fixed_node_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpmJq75zXjmT"
   },
   "source": [
    "### Create Entity Types\n",
    "\n",
    "Entity types can be created within the Featurestore class. Below, you create the `Users` entity type and `Movies` entity type. Process logs are printed in the output for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GU0oXvINBgPV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating EntityType\n",
      "Create EntityType backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/operations/3315832881292509184\n",
      "EntityType created. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users\n",
      "To use this EntityType in another session:\n",
      "entity_type = aiplatform.EntityType('projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users')\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "# Create the Users entity type\n",
    "users_entity_type = movie_predictions_feature_store.create_entity_type(\n",
    "    entity_type_id=\"users\",\n",
    "    description=\"Users entity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qPCGFznrFwFy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating EntityType\n",
      "Create EntityType backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies/operations/7321784749838565376\n",
      "EntityType created. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies\n",
      "To use this EntityType in another session:\n",
      "entity_type = aiplatform.EntityType('projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies')\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "# Create the Movies entity type\n",
    "movies_entity_type = movie_predictions_feature_store.create_entity_type(\n",
    "    entity_type_id=\"movies\",\n",
    "    description=\"Movies entity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJW4q-0jO2Xf"
   },
   "source": [
    "### Create Features\n",
    "Features can be created within each entity type. Add defining features to the `Users` entity type and `Movies` entity type by using the following methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PvjwT84iVSps"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Feature\n",
      "Create Feature backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/age/operations/4684364218059718656\n",
      "Feature created. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/age\n",
      "To use this Feature in another session:\n",
      "feature = aiplatform.Feature('projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/age')\n",
      "Creating Feature\n",
      "Create Feature backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/gender/operations/6452590021756059648\n",
      "Feature created. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/gender\n",
      "To use this Feature in another session:\n",
      "feature = aiplatform.Feature('projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/gender')\n",
      "Creating Feature\n",
      "Create Feature backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/liked_genres/operations/7846454106427228160\n",
      "Feature created. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/liked_genres\n",
      "To use this Feature in another session:\n",
      "feature = aiplatform.Feature('projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/features/liked_genres')\n"
     ]
    }
   ],
   "source": [
    "users_feature_age = users_entity_type.create_feature(\n",
    "    feature_id=\"age\",\n",
    "    value_type=\"INT64\",\n",
    "    description=\"User age\",\n",
    ")\n",
    "\n",
    "users_feature_gender = users_entity_type.create_feature(\n",
    "    feature_id=\"gender\",\n",
    "    value_type=\"STRING\",\n",
    "    description=\"User gender\",\n",
    ")\n",
    "\n",
    "users_feature_liked_genres = users_entity_type.create_feature(\n",
    "    feature_id=\"liked_genres\",\n",
    "    value_type=\"STRING_ARRAY\",\n",
    "    description=\"An array of genres this user liked\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "llTT9_Dgbac2"
   },
   "outputs": [],
   "source": [
    "movies_feature_configs = {\n",
    "    \"title\": {\n",
    "        \"value_type\": \"STRING\",\n",
    "        \"description\": \"The title of the movie\",\n",
    "    },\n",
    "    \"genres\": {\n",
    "        \"value_type\": \"STRING\",\n",
    "        \"description\": \"The genre of the movie\",\n",
    "    },\n",
    "    \"average_rating\": {\n",
    "        \"value_type\": \"DOUBLE\",\n",
    "        \"description\": \"The average rating for the movie, range is [1.0-5.0]\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YhfOKJL_BvuM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch creating features EntityType entityType: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies\n",
      "Batch create Features EntityType entityType backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies/operations/8171839179504746496\n",
      "EntityType entityType Batch created features. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies\n"
     ]
    }
   ],
   "source": [
    "movie_features = movies_entity_type.batch_create_features(\n",
    "    feature_configs=movies_feature_configs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3n5XdK8Xjmw"
   },
   "source": [
    "## Ingest Feature Values into Entity Type from a Pandas DataFrame\n",
    "\n",
    "You need to ingest feature values into your entity type containing the features, so you can later `read` (online) or `batch serve` (offline) the feature values from the entity type. In this step, you will learn how to ingest feature values from a Pandas DataFrame into an entity type. We can also import feature values from BigQuery or Google Cloud Storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlqJ-QdTcs6W"
   },
   "source": [
    "#### Get data from source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_uNrHqiGXrff"
   },
   "outputs": [],
   "source": [
    "GCS_USERS_AVRO_URI = (\n",
    "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro\"\n",
    ")\n",
    "GCS_MOVIES_AVRO_URI = (\n",
    "    \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro\"\n",
    ")\n",
    "\n",
    "USERS_AVRO_FN = \"users.avro\"\n",
    "MOVIES_AVRO_FN = \"movies.avro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KqIH_bS-5OW5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro...\n",
      "/ [1 files][  637.0 B/  637.0 B]                                                \n",
      "Operation completed over 1 objects/637.0 B.                                      \n",
      "Copying gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro...\n",
      "/ [1 files][  599.0 B/  599.0 B]                                                \n",
      "Operation completed over 1 objects/599.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp $GCS_USERS_AVRO_URI $USERS_AVRO_FN\n",
    "! gsutil cp $GCS_MOVIES_AVRO_URI $MOVIES_AVRO_FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd6Z0jfR5OW5"
   },
   "source": [
    "#### Load Avro Files into Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting avro\n",
      "  Downloading avro-1.11.3.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: avro\n",
      "  Building wheel for avro (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro: filename=avro-1.11.3-py2.py3-none-any.whl size=123912 sha256=447ed13ad2b15d4402eeea633104f0f55ae46c797f5c83e244f288e49c90b1b9\n",
      "  Stored in directory: /home/gcpuser/.cache/pip/wheels/1d/f6/41/0e0399396af07060e64d4e32c8bd259b48b98a4a114df31294\n",
      "Successfully built avro\n",
      "Installing collected packages: avro\n",
      "Successfully installed avro-1.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KrB7bnqbZYaC"
   },
   "outputs": [],
   "source": [
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "\n",
    "\n",
    "class AvroReader:\n",
    "    def __init__(self, data_file):\n",
    "        self.avro_reader = DataFileReader(open(data_file, \"rb\"), DatumReader())\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        records = [record for record in self.avro_reader]\n",
    "        return pd.DataFrame.from_records(data=records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XdlWJhUt5OW5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   age  gender               liked_genres  \\\n",
      "0     dave   NaN    None  [Children's, Documentary]   \n",
      "1    alice   NaN    None            [Drama, Comedy]   \n",
      "2  charlie   NaN    None        [Sci-Fi, Animation]   \n",
      "3      bob   NaN    None            [Action, Crime]   \n",
      "4      eve  26.0    None                   [Horror]   \n",
      "5      bob  35.0    Male        [Action, Adventure]   \n",
      "6    alice  55.0  Female                    [Drama]   \n",
      "\n",
      "                       update_time  \n",
      "0 2021-08-20 20:58:22.261581+00:00  \n",
      "1 2021-08-20 20:58:22.261581+00:00  \n",
      "2 2021-08-20 20:58:22.261581+00:00  \n",
      "3 2021-08-20 20:58:22.261581+00:00  \n",
      "4 2021-08-20 20:58:22.261581+00:00  \n",
      "5 2021-08-20 20:58:22.261581+00:00  \n",
      "6 2021-08-20 20:58:22.261581+00:00  \n"
     ]
    }
   ],
   "source": [
    "users_avro_reader = AvroReader(data_file=USERS_AVRO_FN)\n",
    "users_source_df = users_avro_reader.to_dataframe()\n",
    "print(users_source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gZ49cPS35OW5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id  average_rating                     title   genres  \\\n",
      "0  movie_02             4.2               The Shining   Horror   \n",
      "1  movie_04             4.6           The Dark Knight   Action   \n",
      "2  movie_03             4.5           Cinema Paradiso  Romance   \n",
      "3  movie_01             4.9  The Shawshank Redemption    Drama   \n",
      "\n",
      "                       update_time  \n",
      "0 2021-08-20 20:44:11.094375+00:00  \n",
      "1 2021-08-20 20:44:11.094375+00:00  \n",
      "2 2021-08-20 20:44:11.094375+00:00  \n",
      "3 2021-08-20 20:44:11.094375+00:00  \n"
     ]
    }
   ],
   "source": [
    "movies_avro_reader = AvroReader(data_file=MOVIES_AVRO_FN)\n",
    "movies_source_df = movies_avro_reader.to_dataframe()\n",
    "print(movies_source_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgb0WGwX5OW6"
   },
   "source": [
    "#### Ingest Feature Values into _Users_ Entity Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "76b813uj5OW6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received datetime-like column in the dataframe. Please note that the column could be interpreted differently in BigQuery depending on which major version you are using. For more information, please reference the BigQuery v3 release notes here: https://github.com/googleapis/python-bigquery/releases/tag/v3.0.0\n",
      "Importing EntityType feature values: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users\n",
      "Import EntityType feature values backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users/operations/5997726459391639552\n",
      "EntityType feature values imported. Resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.featurestore.entity_type.EntityType object at 0x7fd6415a1ed0> \n",
       "resource name: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/users"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "# Ingest Feature Values into Users Entity Type\n",
    "users_entity_type.ingest_from_df(\n",
    "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
    "    feature_time=\"update_time\",\n",
    "    df_source=users_source_df,\n",
    "    entity_id_field=\"user_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCAdQ3cF5OW6"
   },
   "source": [
    "#### Ingest Feature Values into _Movies_ Entity Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DYlKe4e5OW6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received datetime-like column in the dataframe. Please note that the column could be interpreted differently in BigQuery depending on which major version you are using. For more information, please reference the BigQuery v3 release notes here: https://github.com/googleapis/python-bigquery/releases/tag/v3.0.0\n",
      "Importing EntityType feature values: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies\n",
      "Import EntityType feature values backing LRO: projects/117917517031/locations/us-central1/featurestores/movie_predictions/entityTypes/movies/operations/2880109617344413696\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "# Ingest Feature Values into Movies Entity Type\n",
    "movies_entity_type.ingest_from_df(\n",
    "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
    "    feature_time=\"update_time\",\n",
    "    df_source=movies_source_df,\n",
    "    entity_id_field=\"movie_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIYLZwao5OW6"
   },
   "source": [
    "## Read/Online Serve Entity's Feature Values from Vertex AI Online Feature Store\n",
    "\n",
    "Feature Store allows [online serving](https://cloud.google.com/vertex-ai/docs/featurestore/serving-online)\n",
    "which lets you read feature values for small batches of entities. It works well when you want to read values of selected features from an entity or multiple entities in an entity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrR-SY3i58rh"
   },
   "outputs": [],
   "source": [
    "users_read_df = users_entity_type.read(\n",
    "    entity_ids=[\"dave\", \"alice\", \"charlie\", \"bob\", \"eve\"],\n",
    ")\n",
    "print(users_read_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTW6kBxN5OW7"
   },
   "outputs": [],
   "source": [
    "movies_read_df = movies_entity_type.read(\n",
    "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
    "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
    ")\n",
    "print(movies_read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK2Glzkq5OW7"
   },
   "source": [
    "## Batch Serve Feature Values from Vertex AI Feature Store\n",
    "\n",
    "Batch Serving is used to fetch a large batch of feature values for high-throughput, and is typically used for training a model or batch prediction. In this section, you learn how to prepare training examples by using the Feature Store's batch serve function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxsotHUe5OW7"
   },
   "source": [
    "#### Read instances from source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4k2QVN-5OW7"
   },
   "outputs": [],
   "source": [
    "GCS_READ_INSTANCES_CSV_URI = \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movie_prediction.csv\"\n",
    "READ_INSTANCES_CSV_FN = \"data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rr8XDjk_5OW7"
   },
   "outputs": [],
   "source": [
    "! gsutil cp $GCS_READ_INSTANCES_CSV_URI $READ_INSTANCES_CSV_FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5DW1MFt5OW7"
   },
   "source": [
    "#### Load CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqQVfRnC5OW7"
   },
   "outputs": [],
   "source": [
    "#5\n",
    "read_instances_df = pd.read_csv(READ_INSTANCES_CSV_FN)\n",
    "print(read_instances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsgNNH8G5OW8"
   },
   "source": [
    "#### Change the Dtype of `Timestamp` to `Datetime64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vb9ntNEA5OW8"
   },
   "outputs": [],
   "source": [
    "print(\"before: \", read_instances_df[\"timestamp\"].dtype)\n",
    "read_instances_df = read_instances_df.astype({\"timestamp\": \"datetime64\"})\n",
    "print(\"after:  \", read_instances_df[\"timestamp\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ao1dC5Pc5OW8"
   },
   "source": [
    "#### Batch Serve Feature Values from Movie Predictions Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZSJ-Sbl5OW8"
   },
   "outputs": [],
   "source": [
    "movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
    "    serving_feature_ids={\n",
    "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
    "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
    "    },\n",
    "    read_instances_df=read_instances_df,\n",
    ")\n",
    "movie_predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29gLNORP5OW8"
   },
   "source": [
    "## Read the Updated Feature Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XN84znoI5OW8"
   },
   "source": [
    "#### Feature Values from last ingestion\n",
    "Recall read from the Entity Type shows Feature Values from the last ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtmshq_n5OW9"
   },
   "outputs": [],
   "source": [
    "print(movies_read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feTUJjqG5OW9"
   },
   "source": [
    "#### Ingest updated Feature Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Y-iMUFH5OW9"
   },
   "outputs": [],
   "source": [
    "update_movies_df = pd.DataFrame(\n",
    "    data=[[\"movie_03\", 4.3], [\"movie_04\", 4.8]],\n",
    "    columns=[\"movie_id\", \"average_rating\"],\n",
    ")\n",
    "print(update_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKKhSzUc5OW9"
   },
   "outputs": [],
   "source": [
    "movies_entity_type.ingest_from_df(\n",
    "    feature_ids=[\"average_rating\"],\n",
    "    feature_time=datetime.datetime.now(),\n",
    "    df_source=update_movies_df,\n",
    "    entity_id_field=\"movie_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s47WCIvL5OW9"
   },
   "source": [
    "#### Latest Feature Values\n",
    "Read from the Entity Type shows updated Feature values from the latest ingestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2IPEY7S5OW9"
   },
   "outputs": [],
   "source": [
    "update_movies_read_df = movies_entity_type.read(\n",
    "    entity_ids=[\"movie_01\", \"movie_02\", \"movie_03\", \"movie_04\"],\n",
    "    feature_ids=[\"title\", \"genres\", \"average_rating\"],\n",
    ")\n",
    "print(update_movies_read_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsvCRzn_5OW9"
   },
   "source": [
    "## Point-in-Time Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1YGRNsW5OW9"
   },
   "source": [
    "#### Missing data\n",
    "Recall Batch Serve from the last ingestion has some missing data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueXYomBr5OW-"
   },
   "outputs": [],
   "source": [
    "print(movie_predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abQRF6mx5OW-"
   },
   "source": [
    "#### Backfill/Correct point-in-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehZhc4ZP5OW-"
   },
   "outputs": [],
   "source": [
    "backfill_users_df = pd.DataFrame(\n",
    "    data=[[\"bob\", 34, \"Male\", [\"Drama\"], \"2020-02-13 09:35:15\"]],\n",
    "    columns=[\"user_id\", \"age\", \"gender\", \"liked_genres\", \"update_time\"],\n",
    ")\n",
    "backfill_users_df = backfill_users_df.astype({\"update_time\": \"datetime64\"})\n",
    "print(backfill_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhdTzl5k5OW-"
   },
   "outputs": [],
   "source": [
    "backfill_movies_df = pd.DataFrame(\n",
    "    data=[[\"movie_04\", 4.2, \"The Dark Knight\", \"Action\", \"2020-02-13 09:35:15\"]],\n",
    "    columns=[\"movie_id\", \"average_rating\", \"title\", \"genres\", \"update_time\"],\n",
    ")\n",
    "backfill_movies_df = backfill_movies_df.astype({\"update_time\": \"datetime64\"})\n",
    "print(backfill_movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXb4JUhu5OW-"
   },
   "source": [
    "#### Ingest backfilled/corrected point-in-time data from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vM1ejZMa5OW-"
   },
   "outputs": [],
   "source": [
    "users_entity_type.ingest_from_df(\n",
    "    feature_ids=[\"age\", \"gender\", \"liked_genres\"],\n",
    "    feature_time=\"update_time\",\n",
    "    df_source=backfill_users_df,\n",
    "    entity_id_field=\"user_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBnrNbv75OW-"
   },
   "outputs": [],
   "source": [
    "movies_entity_type.ingest_from_df(\n",
    "    feature_ids=[\"average_rating\", \"title\", \"genres\"],\n",
    "    feature_time=\"update_time\",\n",
    "    df_source=backfill_movies_df,\n",
    "    entity_id_field=\"movie_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e62Ku6W5OW_"
   },
   "source": [
    "#### Latest ingestion with imputed missing data\n",
    "Batch Serve from the latest ingestion with backfill/correction has reduced missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3njvLv2wbZok"
   },
   "outputs": [],
   "source": [
    "backfill_movie_predictions_df = movie_predictions_feature_store.batch_serve_to_df(\n",
    "    serving_feature_ids={\n",
    "        \"users\": [\"age\", \"gender\", \"liked_genres\"],\n",
    "        \"movies\": [\"title\", \"average_rating\", \"genres\"],\n",
    "    },\n",
    "    read_instances_df=read_instances_df,\n",
    ")\n",
    "print(backfill_movie_predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "You can also keep the project but delete the featurestore by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NBTNfN8vxz4x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Featurestore : projects/816732343711/locations/us-central1/featurestores/movie_predictions\n",
      "Delete Featurestore  backing LRO: projects/816732343711/locations/us-central1/operations/1667699998189420544\n",
      "Featurestore deleted. . Resource name: projects/816732343711/locations/us-central1/featurestores/movie_predictions\n"
     ]
    }
   ],
   "source": [
    "movie_predictions_feature_store.delete(force=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sdk-feature-store-pandas.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m95"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMYQvJuBi7MS"
   },
   "source": [
    "# Feature Engineering using Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nna1tOKxyEqe"
   },
   "source": [
    "\n",
    "## Learning objectives\n",
    "\n",
    "1. Load a CSV file using [Pandas](https://pandas.pydata.org/).\n",
    "2. Build an input pipeline to batch and shuffle the rows using [tf.data](https://www.tensorflow.org/guide/datasets).\n",
    "3. Map from columns in the CSV to features used to train the model using Keras Preprocessing layers.\n",
    "4. Build, train, and evaluate a model using Keras.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you learn how to classify structured data (e.g. tabular data in a CSV). You will use [Keras](https://www.tensorflow.org/guide/keras) to define the model, and [preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) as a bridge to map from columns in a CSV to features used to train the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHxU1FMNpomc"
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "You will use a simplified version of the PetFinder [dataset](https://www.kaggle.com/c/petfinder-adoption-prediction). There are several thousand rows in the CSV. Each row describes a pet, and each column describes an attribute. You will use this information to predict if the pet will be adopted.\n",
    "\n",
    "Following is a description of this dataset. Notice there are both numeric and categorical columns\n",
    "\n",
    "Column | Description| Feature Type | Data Type\n",
    "------------|--------------------|----------------------|-----------------\n",
    "Type | Type of animal (Dog, Cat) | Categorical | string\n",
    "Age |  Age of the pet | Numerical | integer\n",
    "Breed1 | Primary breed of the pet | Categorical | string\n",
    "Color1 | Color 1 of pet | Categorical | string\n",
    "Color2 | Color 2 of pet | Categorical | string\n",
    "MaturitySize | Size at maturity | Categorical | string\n",
    "FurLength | Fur length | Categorical | string\n",
    "Vaccinated | Pet has been vaccinated | Categorical | string\n",
    "Sterilized | Pet has been sterilized | Categorical | string\n",
    "Health | Health Condition | Categorical | string\n",
    "Fee | Adoption Fee | Numerical | integer\n",
    "Description | Profile write-up for this pet | Text | string\n",
    "PhotoAmt | Total uploaded photos for this pet | Numerical | integer\n",
    "AdoptionSpeed | Speed of adoption | Classification | integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjFbdBldyEqf"
   },
   "source": [
    "## Import TensorFlow and other libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LklnLlt6yEqf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 10:29:05.683192: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-25 10:29:05.737199: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-25 10:29:05.737239: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-25 10:29:05.737271: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-25 10:29:05.746677: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-25 10:29:05.747509: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 10:29:07.103909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TKU7RyoQGVKB",
    "outputId": "e857c1fe-b68d-4746-bed7-eb28642f9bfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the tensorflow version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXvBvobayEqi"
   },
   "source": [
    "## Use Pandas to create a dataframe\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a Python library with many helpful utilities for loading and working with structured data. You will use Pandas to download the dataset from a URL, and load it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJ4Ajn-YyEqj",
    "outputId": "4d0de1f2-f9f2-412c-e526-a838a4ba670a"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'gs://cloud-training/mlongcp/v3.0_MLonGC/toy_data/petfinder-mini_toy.csv'\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,\n",
    "                        extract=True, cache_dir='.')\n",
    "# read a comma-separated values (csv) file into DataFrame\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "3uiq4hoIGyXI",
    "outputId": "52379c9e-3c20-479e-bf65-8c6ebeccdcd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  \\\n",
       "0     Short         No         No  Healthy  100   \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0   \n",
       "2    Medium        Yes         No  Healthy    0   \n",
       "3     Short        Yes         No  Healthy  150   \n",
       "4     Short         No         No  Healthy    0   \n",
       "\n",
       "                                         Description  PhotoAmt  AdoptionSpeed  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...         1              2  \n",
       "1  I just found it alone yesterday near my apartm...         2              0  \n",
       "2  Their pregnant mother was dumped by her irresp...         7              3  \n",
       "3  Good guard dog, very alert, active, obedience ...         8              2  \n",
       "4  This handsome yet cute boy is up for adoption....         3              2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first n rows\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3zDbrozyEqq"
   },
   "source": [
    "## Create target variable\n",
    "\n",
    "Predict whether the pet was adopted, or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wmMDc46-yEqq"
   },
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "dataframe['target'] = dataframe['Fee']\n",
    "\n",
    "# Drop un-used columns.\n",
    "dataframe = dataframe.drop(columns=['Fee', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>Cat</td>\n",
       "      <td>12</td>\n",
       "      <td>Domestic Short Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Golden</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Long</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Cat</td>\n",
       "      <td>5</td>\n",
       "      <td>Domestic Short Hair</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Dog</td>\n",
       "      <td>27</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Golden</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Dog</td>\n",
       "      <td>2</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Type  Age                Breed1  Gender  Color1    Color2 MaturitySize  \\\n",
       "0     Cat    3                 Tabby    Male   Black     White        Small   \n",
       "1     Cat    1  Domestic Medium Hair    Male   Black     Brown       Medium   \n",
       "2     Dog    1           Mixed Breed    Male   Brown     White       Medium   \n",
       "3     Dog    4           Mixed Breed  Female   Black     Brown       Medium   \n",
       "4     Dog    1           Mixed Breed    Male   Black  No Color       Medium   \n",
       "...   ...  ...                   ...     ...     ...       ...          ...   \n",
       "4994  Cat   12   Domestic Short Hair    Male   White  No Color       Medium   \n",
       "4995  Cat    1               Persian  Female  Golden      Gray       Medium   \n",
       "4996  Cat    5   Domestic Short Hair  Female   Black  No Color       Medium   \n",
       "4997  Dog   27           Mixed Breed  Female  Golden  No Color       Medium   \n",
       "4998  Dog    2           Mixed Breed    Male   Black     White       Medium   \n",
       "\n",
       "     FurLength Vaccinated Sterilized   Health  PhotoAmt  AdoptionSpeed  target  \n",
       "0        Short         No         No  Healthy         1              2     100  \n",
       "1       Medium   Not Sure   Not Sure  Healthy         2              0       0  \n",
       "2       Medium        Yes         No  Healthy         7              3       0  \n",
       "3        Short        Yes         No  Healthy         8              2     150  \n",
       "4        Short         No         No  Healthy         3              2       0  \n",
       "...        ...        ...        ...      ...       ...            ...     ...  \n",
       "4994     Short        Yes        Yes  Healthy         1              4       0  \n",
       "4995      Long        Yes         No  Healthy         6              3     150  \n",
       "4996    Medium        Yes        Yes  Healthy         4              2       0  \n",
       "4997     Short        Yes        Yes  Healthy         4              4       0  \n",
       "4998     Short   Not Sure         No  Healthy         2              2       0  \n",
       "\n",
       "[4999 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp0NCbswyEqs"
   },
   "source": [
    "## Split the dataframe into train, validation, and test\n",
    "\n",
    "The dataset you downloaded was a single CSV file. You will split this into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qT6HdyEwyEqt",
    "outputId": "c3008199-bf30-48cc-d55a-8ae2a35ab699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3199 train examples\n",
      "800 validation examples\n",
      "1000 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_7uVu-xyEqv"
   },
   "source": [
    "## Create an input pipeline using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7r4j-1lRyEqw"
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('target')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYxIXH579uS9"
   },
   "source": [
    "Now that you have created the input pipeline, let's call it to see the format of the data it returns. You have used a small batch size to keep the output readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tYiNH-QI96Jo"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "# call the necessary function with required parameters\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFYir6S8HgIJ",
    "outputId": "a74940a9-7585-4973-e1f3-8164daa84f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'PhotoAmt', 'AdoptionSpeed']\n",
      "A batch of ages: tf.Tensor([ 3 48 12 16 36], shape=(5,), dtype=int64)\n",
      "A batch of targets: tf.Tensor([ 0  0  0 50  0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['Age'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geqHWW54Hmte"
   },
   "source": [
    "You can see that the dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v50jBIuj4gb"
   },
   "source": [
    "## Demonstrate the use of preprocessing layers.\n",
    "\n",
    "The Keras preprocessing layers API allows you to build Keras-native input processing pipelines. You will use 3 preprocessing layers to demonstrate the feature preprocessing code.\n",
    "\n",
    "*   [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) - Feature-wise normalization of the data.\n",
    "*   [`CategoryEncoding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CategoryEncoding) - Category encoding layer.\n",
    "*   [`StringLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/StringLookup) - Maps strings from a vocabulary to integer indices.\n",
    "*   [`IntegerLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/IntegerLookup) - Maps integers from a vocabulary to integer indices.\n",
    "\n",
    "You can find a list of available preprocessing layers [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twXBSxnT66o8"
   },
   "source": [
    "### Numeric columns\n",
    "For each of the Numeric feature, you will use a Normalization() layer to make sure the mean of each feature is 0 and its standard deviation is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OosUh4kTsK_q"
   },
   "source": [
    "`get_normalization_layer` function returns a layer which applies featurewise normalization to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "D6OuEKMMyEq1"
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for our feature.\n",
    "  normalizer = preprocessing.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpKgUDyk69bM",
    "outputId": "fced3061-aded-4438-fdb5-cdcc70472fa8"
   },
   "outputs": [],
   "source": [
    "#layer = get_normalization_layer('PhotoAmt', train_ds)\n",
    "#layer(train_features['PhotoAmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer = get_normalization_layer('Fee', train_ds)\n",
    "#layer(train_features['Fee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWY00YBUx9N"
   },
   "source": [
    "Note: If you many numeric features (hundreds, or more), it is more efficient to concatenate them first and use a single [normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVD--2WZ7vmh"
   },
   "source": [
    "### Categorical columns\n",
    "In this dataset, Type is represented as a string (e.g. 'Dog', or 'Cat'). You cannot feed strings directly to a model. The preprocessing layer takes care of representing strings as a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWlkOPwMsxdv"
   },
   "source": [
    "`get_category_encoding_layer` function returns a layer which maps values from a vocabulary to integer indices and one-hot encodes the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GmgaeRjlDoUO"
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a StringLookup layer which will turn strings into integer indices\n",
    "  if dtype == 'string':\n",
    "    index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "  else:\n",
    "    index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a Dataset that only yields our feature\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Create a Discretization for our integer indices.\n",
    "  encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "  # layer so we can use them, or include them in the functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2t2ff9K8PcT",
    "outputId": "f4294791-555a-40ee-a731-da55f8258729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Type']\n",
    "layer = get_category_encoding_layer('Type', train_ds, 'string')\n",
    "layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6eDongw8knz"
   },
   "source": [
    "Often, you don't want to feed a number directly into the model, but instead use a one-hot encoding of those inputs. Consider raw data that represents a pet's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FjBioQ38oNE",
    "outputId": "6cc6f424-ddcb-487e-de32-d94a255f7ecb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=float32, numpy=array([1., 0., 1., 0., 0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_col = train_features['Age']\n",
    "category_encoding_layer = get_category_encoding_layer('Age', train_ds,\n",
    "                                                      'int64', 7)\n",
    "category_encoding_layer(type_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiE0glOPkMyh"
   },
   "source": [
    "## Choose which columns to use\n",
    "You have seen how to use several types of preprocessing layers. Now you will use them to train a model. You will be using [Keras-functional API](https://www.tensorflow.org/guide/keras/functional) to build the model. The Keras functional API is a way to create models that are more flexible than the [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Rcv2kQTTo23h"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Q3RBa51VkaAn"
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numeric features.\n",
    "for header in ['PhotoAmt', 'AdoptionSpeed']:\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, train_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1FOMGfZflhoA"
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers.\n",
    "age_col = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
    "encoding_layer = get_category_encoding_layer('Age', train_ds, dtype='int64',\n",
    "                                             max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "K8C8xyiXm-Ie"
   },
   "outputs": [],
   "source": [
    "# Categorical features encoded as string.\n",
    "categorical_cols = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1']\n",
    "for header in categorical_cols:\n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string',\n",
    "                                               max_tokens=5)\n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHSnhz2fyEq3"
   },
   "source": [
    "## Create, compile, and train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDGyN_wpo0XS"
   },
   "source": [
    "Now you can create our end-to-end model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "6Yrj-_pr6jyL"
   },
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "# TODO\n",
    "# compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CED6OStLyEq7"
   },
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQfE3PC6yEq8",
    "outputId": "38dc5150-a913-48df-ca86-4b260487afed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 2s 48ms/step - loss: -24.4559 - accuracy: 0.2513 - val_loss: -32.0746 - val_accuracy: 0.0113\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -41.7032 - accuracy: 0.0713 - val_loss: -50.1026 - val_accuracy: 0.0037\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -61.0942 - accuracy: 0.0216 - val_loss: -71.7414 - val_accuracy: 0.0037\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -90.1765 - accuracy: 0.0088 - val_loss: -98.8272 - val_accuracy: 0.0037\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -127.3690 - accuracy: 0.0063 - val_loss: -133.6194 - val_accuracy: 0.0037\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -164.3114 - accuracy: 0.0056 - val_loss: -177.8032 - val_accuracy: 0.0037\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -220.3429 - accuracy: 0.0056 - val_loss: -233.7592 - val_accuracy: 0.0037\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -272.0713 - accuracy: 0.0056 - val_loss: -300.9760 - val_accuracy: 0.0037\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -352.6962 - accuracy: 0.0056 - val_loss: -380.5529 - val_accuracy: 0.0037\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -448.8411 - accuracy: 0.0056 - val_loss: -477.2141 - val_accuracy: 0.0037\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -564.6382 - accuracy: 0.0056 - val_loss: -591.4066 - val_accuracy: 0.0037\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -682.3503 - accuracy: 0.0056 - val_loss: -722.4949 - val_accuracy: 0.0037\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -846.4799 - accuracy: 0.0056 - val_loss: -873.6418 - val_accuracy: 0.0037\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -986.8823 - accuracy: 0.0056 - val_loss: -1041.6418 - val_accuracy: 0.0037\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -1208.0940 - accuracy: 0.0056 - val_loss: -1228.1023 - val_accuracy: 0.0037\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -1444.6504 - accuracy: 0.0056 - val_loss: -1436.2689 - val_accuracy: 0.0037\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -1675.3092 - accuracy: 0.0056 - val_loss: -1673.7578 - val_accuracy: 0.0037\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -1862.8853 - accuracy: 0.0056 - val_loss: -1927.4418 - val_accuracy: 0.0037\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -2167.2825 - accuracy: 0.0056 - val_loss: -2203.3376 - val_accuracy: 0.0037\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -2495.3003 - accuracy: 0.0056 - val_loss: -2514.1145 - val_accuracy: 0.0037\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -2857.9119 - accuracy: 0.0056 - val_loss: -2850.5264 - val_accuracy: 0.0037\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -3206.2000 - accuracy: 0.0056 - val_loss: -3213.7112 - val_accuracy: 0.0037\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -3552.9207 - accuracy: 0.0056 - val_loss: -3607.6572 - val_accuracy: 0.0037\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -4089.6553 - accuracy: 0.0056 - val_loss: -4042.5137 - val_accuracy: 0.0037\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -4537.8716 - accuracy: 0.0056 - val_loss: -4509.0063 - val_accuracy: 0.0037\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -5050.3291 - accuracy: 0.0056 - val_loss: -5002.6792 - val_accuracy: 0.0037\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -5600.8208 - accuracy: 0.0056 - val_loss: -5548.4561 - val_accuracy: 0.0037\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -6183.5635 - accuracy: 0.0056 - val_loss: -6120.7402 - val_accuracy: 0.0037\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -6816.5034 - accuracy: 0.0056 - val_loss: -6724.0142 - val_accuracy: 0.0037\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -7534.5127 - accuracy: 0.0056 - val_loss: -7375.4556 - val_accuracy: 0.0037\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -8273.0410 - accuracy: 0.0056 - val_loss: -8056.2549 - val_accuracy: 0.0037\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -8922.5615 - accuracy: 0.0056 - val_loss: -8770.1035 - val_accuracy: 0.0037\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -9735.3184 - accuracy: 0.0056 - val_loss: -9522.0859 - val_accuracy: 0.0037\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -10412.8105 - accuracy: 0.0056 - val_loss: -10317.4385 - val_accuracy: 0.0037\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -11475.6758 - accuracy: 0.0056 - val_loss: -11169.5547 - val_accuracy: 0.0037\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -12482.9570 - accuracy: 0.0056 - val_loss: -12069.3633 - val_accuracy: 0.0037\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -13452.7393 - accuracy: 0.0056 - val_loss: -13039.3027 - val_accuracy: 0.0037\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -14351.9922 - accuracy: 0.0056 - val_loss: -14017.4297 - val_accuracy: 0.0037\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: -15772.6191 - accuracy: 0.0056 - val_loss: -15066.8584 - val_accuracy: 0.0037\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -16594.1133 - accuracy: 0.0056 - val_loss: -16189.0322 - val_accuracy: 0.0037\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -18244.8008 - accuracy: 0.0056 - val_loss: -17363.0859 - val_accuracy: 0.0037\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -19187.5352 - accuracy: 0.0056 - val_loss: -18540.7949 - val_accuracy: 0.0037\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -20044.5566 - accuracy: 0.0056 - val_loss: -19768.3418 - val_accuracy: 0.0037\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -21381.8770 - accuracy: 0.0056 - val_loss: -21027.8926 - val_accuracy: 0.0037\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -23508.0879 - accuracy: 0.0056 - val_loss: -22378.6074 - val_accuracy: 0.0037\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -24980.3809 - accuracy: 0.0056 - val_loss: -23766.0371 - val_accuracy: 0.0037\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -26222.0723 - accuracy: 0.0056 - val_loss: -25247.1777 - val_accuracy: 0.0037\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -27793.2148 - accuracy: 0.0056 - val_loss: -26757.7949 - val_accuracy: 0.0037\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -29543.6172 - accuracy: 0.0056 - val_loss: -28282.1016 - val_accuracy: 0.0037\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -32068.7344 - accuracy: 0.0056 - val_loss: -29909.1953 - val_accuracy: 0.0037\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -32569.9629 - accuracy: 0.0056 - val_loss: -31591.3398 - val_accuracy: 0.0037\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -33665.9180 - accuracy: 0.0056 - val_loss: -33243.2305 - val_accuracy: 0.0037\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -36611.6094 - accuracy: 0.0056 - val_loss: -34964.7109 - val_accuracy: 0.0037\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -38289.7148 - accuracy: 0.0056 - val_loss: -36777.6836 - val_accuracy: 0.0037\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -40578.7500 - accuracy: 0.0056 - val_loss: -38718.9531 - val_accuracy: 0.0037\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -42080.3906 - accuracy: 0.0056 - val_loss: -40624.0312 - val_accuracy: 0.0037\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -43150.5508 - accuracy: 0.0056 - val_loss: -42606.5469 - val_accuracy: 0.0037\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: -47356.7227 - accuracy: 0.0056 - val_loss: -44680.9609 - val_accuracy: 0.0037\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: -49009.0039 - accuracy: 0.0056 - val_loss: -46813.4609 - val_accuracy: 0.0037\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -51220.9297 - accuracy: 0.0056 - val_loss: -48958.2188 - val_accuracy: 0.0037\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -52713.2227 - accuracy: 0.0056 - val_loss: -51213.2188 - val_accuracy: 0.0037\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -55264.1992 - accuracy: 0.0056 - val_loss: -53495.2305 - val_accuracy: 0.0037\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -57155.3320 - accuracy: 0.0056 - val_loss: -55850.3906 - val_accuracy: 0.0037\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -60022.5820 - accuracy: 0.0056 - val_loss: -58286.1250 - val_accuracy: 0.0037\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -64301.8281 - accuracy: 0.0056 - val_loss: -60813.8047 - val_accuracy: 0.0037\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -67165.3828 - accuracy: 0.0056 - val_loss: -63356.4414 - val_accuracy: 0.0037\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -70018.4922 - accuracy: 0.0056 - val_loss: -66099.6797 - val_accuracy: 0.0037\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -72342.4219 - accuracy: 0.0056 - val_loss: -68791.5625 - val_accuracy: 0.0037\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -75407.5625 - accuracy: 0.0056 - val_loss: -71564.8984 - val_accuracy: 0.0037\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -77692.6484 - accuracy: 0.0056 - val_loss: -74494.5078 - val_accuracy: 0.0037\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -81066.0469 - accuracy: 0.0056 - val_loss: -77427.4844 - val_accuracy: 0.0037\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -84303.7344 - accuracy: 0.0056 - val_loss: -80363.9688 - val_accuracy: 0.0037\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -87218.9453 - accuracy: 0.0056 - val_loss: -83453.8750 - val_accuracy: 0.0037\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -89816.5703 - accuracy: 0.0056 - val_loss: -86540.3281 - val_accuracy: 0.0037\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -94141.1562 - accuracy: 0.0056 - val_loss: -89762.6406 - val_accuracy: 0.0037\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -99872.1016 - accuracy: 0.0056 - val_loss: -93045.1797 - val_accuracy: 0.0037\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -102205.0000 - accuracy: 0.0056 - val_loss: -96361.9766 - val_accuracy: 0.0037\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -105636.8828 - accuracy: 0.0056 - val_loss: -99806.0703 - val_accuracy: 0.0037\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -109974.4688 - accuracy: 0.0056 - val_loss: -103365.7188 - val_accuracy: 0.0037\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -108898.5000 - accuracy: 0.0056 - val_loss: -106895.6172 - val_accuracy: 0.0037\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: -115927.1797 - accuracy: 0.0056 - val_loss: -110475.5000 - val_accuracy: 0.0037\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -120538.3203 - accuracy: 0.0056 - val_loss: -114199.5312 - val_accuracy: 0.0037\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -125414.4688 - accuracy: 0.0056 - val_loss: -118019.2031 - val_accuracy: 0.0037\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -128451.8984 - accuracy: 0.0056 - val_loss: -121986.7891 - val_accuracy: 0.0037\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -129900.7734 - accuracy: 0.0056 - val_loss: -125908.1719 - val_accuracy: 0.0037\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -133046.8281 - accuracy: 0.0056 - val_loss: -129864.2266 - val_accuracy: 0.0037\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -139863.3438 - accuracy: 0.0056 - val_loss: -133816.2656 - val_accuracy: 0.0037\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: -148039.8594 - accuracy: 0.0056 - val_loss: -138020.7656 - val_accuracy: 0.0037\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -149765.0625 - accuracy: 0.0056 - val_loss: -142314.0312 - val_accuracy: 0.0037\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -157059.3594 - accuracy: 0.0056 - val_loss: -146719.0781 - val_accuracy: 0.0037\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -160250.2656 - accuracy: 0.0056 - val_loss: -151170.5938 - val_accuracy: 0.0037\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -164503.8281 - accuracy: 0.0056 - val_loss: -155668.0156 - val_accuracy: 0.0037\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -170755.4844 - accuracy: 0.0056 - val_loss: -160206.4062 - val_accuracy: 0.0037\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -174943.2969 - accuracy: 0.0056 - val_loss: -164980.4531 - val_accuracy: 0.0037\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -180858.2969 - accuracy: 0.0056 - val_loss: -169826.6406 - val_accuracy: 0.0037\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -186632.7188 - accuracy: 0.0056 - val_loss: -174649.5781 - val_accuracy: 0.0037\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -189816.7344 - accuracy: 0.0056 - val_loss: -179534.1562 - val_accuracy: 0.0037\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -194753.6562 - accuracy: 0.0056 - val_loss: -184445.0469 - val_accuracy: 0.0037\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -204023.3438 - accuracy: 0.0056 - val_loss: -189586.7031 - val_accuracy: 0.0037\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: -202267.1719 - accuracy: 0.0056 - val_loss: -194808.0781 - val_accuracy: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f70dba6c5e0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(train_ds, epochs=100, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8N2uAdU2Cni",
    "outputId": "bd3d4ec9-32e5-4903-8b91-d5acf0cc5c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: -162356.7812 - accuracy: 0.0110\n",
      "Accuracy 0.010999999940395355\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmZMnTKaCZda"
   },
   "source": [
    "## Inference on new data\n",
    "\n",
    "Key point: The model you have developed can now classify a row from a CSV file directly, because the preprocessing code is included inside the model itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xkOlK8Zweeh"
   },
   "source": [
    "You can now save and reload the Keras model. Follow the tutorial [here](https://www.tensorflow.org/tutorials/keras/save_and_load) for more information on TensorFlow models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QH9Zy1sBvwOH",
    "outputId": "966ca761-a0f1-498d-97ed-f9e4b8b29785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_pet_classifier/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_pet_classifier/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_pet_classifier')\n",
    "reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D973plJrdwQ9"
   },
   "source": [
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are just two things you need to do:\n",
    "\n",
    "1.   Wrap scalars into a list so as to have a batch dimension (models only process batches of data, not single samples)\n",
    "2.   Call `convert_to_tensor` on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKq4pxtdDa7i",
    "outputId": "068f6499-3894-404b-a26a-ce48486c8fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 482ms/step\n",
      "This particular pet had a 100.0 percent probability of getting adopted.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    'Type': 'Cat',\n",
    "    'Age': 2,\n",
    "    'Breed1': 'Tabby',\n",
    "    'Gender': 'Male',\n",
    "    'Color1': 'Black',\n",
    "    'Color2': 'White',\n",
    "    'MaturitySize': 'Small',\n",
    "    'FurLength': 'Short',\n",
    "    'Vaccinated': 'No',\n",
    "    'Sterilized': 'No',\n",
    "    'Health': 'Unealthy',\n",
    "    'AdoptionSpeed': 20,\n",
    "    'PhotoAmt': 20,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = reloaded_model.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[653.0087]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0QAY2Tb2HYG"
   },
   "source": [
    "## Next steps\n",
    "The best way to learn more about classifying structured data is to try it yourself. You may want to find another dataset to work with, and training a model to classify it using code similar to the above. To improve accuracy, think carefully about which features to include in your model, and how they should be represented."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing_layers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
